{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is Marjaryasana: True\n",
      "Details:\n",
      "- spine_angle: 103.5°\n",
      "- left_leg_angle: 89.7°\n",
      "- right_leg_angle: 85.3°\n",
      "- head_tucked: True\n",
      "- back_rounded: True\n",
      "- knees_under_hips: True\n",
      "- legs_vertical: True\n"
     ]
    }
   ],
   "source": [
    "import mediapipe as mp \n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "class MarjaryasanaDetector:\n",
    "    \"\"\"\n",
    "    A class for detecting and analyzing the Marjaryasana (Cat Pose) yoga pose using MediaPipe.\n",
    "    \n",
    "    This class uses the MediaPipe Pose solution to detect and analyze body landmarks\n",
    "    to determine if a person is correctly performing the Marjaryasana pose.\n",
    "    \n",
    "    Attributes:\n",
    "        mp_pose: MediaPipe pose solution instance\n",
    "        pose: MediaPipe pose detector configured for static images\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        Initialize the MarjaryasanaDetector with MediaPipe pose detection settings.\n",
    "        \"\"\"\n",
    "        self.mp_pose = mp.solutions.pose\n",
    "        self.pose = self.mp_pose.Pose(\n",
    "            static_image_mode=True,  # Set to True for image processing (vs video)\n",
    "            min_detection_confidence=0.5  # Minimum confidence threshold for pose detection\n",
    "        )\n",
    "        \n",
    "    def calculate_angle(self, a, b, c):\n",
    "        \"\"\"\n",
    "        Calculate the angle between three points in 2D space.\n",
    "        \n",
    "        Args:\n",
    "            a (list): First point coordinates [x, y]\n",
    "            b (list): Middle point coordinates [x, y] (vertex of angle)\n",
    "            c (list): Last point coordinates [x, y]\n",
    "            \n",
    "        Returns:\n",
    "            float: Angle in degrees between the three points (0-180)\n",
    "        \"\"\"\n",
    "        a = np.array(a)\n",
    "        b = np.array(b)\n",
    "        c = np.array(c)\n",
    "        \n",
    "        # Calculate angle using arctangent\n",
    "        radians = np.arctan2(c[1]-b[1], c[0]-b[0]) - \\\n",
    "                  np.arctan2(a[1]-b[1], a[0]-b[0])\n",
    "        angle = np.abs(radians*180.0/np.pi)\n",
    "        \n",
    "        # Ensure angle is between 0-180 degrees\n",
    "        if angle > 180.0:\n",
    "            angle = 360-angle\n",
    "            \n",
    "        return angle\n",
    "    \n",
    "    def get_point(self, landmark):\n",
    "        \"\"\"\n",
    "        Convert a MediaPipe landmark to a 2D point.\n",
    "        \n",
    "        Args:\n",
    "            landmark (mediapipe.framework.formats.landmark_pb2.NormalizedLandmark): \n",
    "                MediaPipe landmark object\n",
    "                \n",
    "        Returns:\n",
    "            list: 2D point coordinates [x, y]\n",
    "        \"\"\"\n",
    "        return [landmark.x, landmark.y]\n",
    "\n",
    "    def detect_pose(self, image):\n",
    "        \"\"\"\n",
    "        Detect if a person in the image is performing the Marjaryasana pose.\n",
    "        \n",
    "        The method checks several key characteristics of the pose:\n",
    "        - Head position (tucked)\n",
    "        - Back position (rounded)\n",
    "        - Knee position (under hips)\n",
    "        - Leg alignment (vertical)\n",
    "        \n",
    "        Args:\n",
    "            image (numpy.ndarray): Input BGR image\n",
    "            \n",
    "        Returns:\n",
    "            tuple: (is_marjaryasana, debug_info)\n",
    "                - is_marjaryasana (bool): True if pose detected correctly\n",
    "                - debug_info (dict): Dictionary containing detailed pose measurements\n",
    "                  and intermediate checks\n",
    "        \"\"\"\n",
    "        # Convert BGR to RGB for MediaPipe processing\n",
    "        image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        results = self.pose.process(image_rgb)\n",
    "        \n",
    "        if results.pose_landmarks is None:\n",
    "            return False, \"No pose detected\"\n",
    "            \n",
    "        landmarks = results.pose_landmarks.landmark\n",
    "        \n",
    "        # Extract key anatomical landmarks for pose analysis\n",
    "        nose = landmarks[self.mp_pose.PoseLandmark.NOSE]\n",
    "        left_shoulder = landmarks[self.mp_pose.PoseLandmark.LEFT_SHOULDER]\n",
    "        right_shoulder = landmarks[self.mp_pose.PoseLandmark.RIGHT_SHOULDER]\n",
    "        left_hip = landmarks[self.mp_pose.PoseLandmark.LEFT_HIP]\n",
    "        right_hip = landmarks[self.mp_pose.PoseLandmark.RIGHT_HIP]\n",
    "        left_knee = landmarks[self.mp_pose.PoseLandmark.LEFT_KNEE]\n",
    "        right_knee = landmarks[self.mp_pose.PoseLandmark.RIGHT_KNEE]\n",
    "        left_ankle = landmarks[self.mp_pose.PoseLandmark.LEFT_ANKLE]\n",
    "        right_ankle = landmarks[self.mp_pose.PoseLandmark.RIGHT_ANKLE]\n",
    "        \n",
    "        # Calculate key angles for pose verification\n",
    "        spine_angle = self.calculate_angle(\n",
    "            self.get_point(left_shoulder),\n",
    "            self.get_point(left_hip),\n",
    "            self.get_point(left_knee)\n",
    "        )\n",
    "        \n",
    "        left_leg_angle = self.calculate_angle(\n",
    "            self.get_point(left_hip),\n",
    "            self.get_point(left_knee),\n",
    "            self.get_point(left_ankle)\n",
    "        )\n",
    "        \n",
    "        right_leg_angle = self.calculate_angle(\n",
    "            self.get_point(right_hip),\n",
    "            self.get_point(right_knee),\n",
    "            self.get_point(right_ankle)\n",
    "        )\n",
    "\n",
    "        # Verify key pose characteristics\n",
    "        head_tucked = nose.y > (left_shoulder.y + right_shoulder.y) / 2  # Check if head is below shoulders\n",
    "        back_rounded = 90 <= spine_angle <= 130  # Verify back curvature\n",
    "        knees_under_hips = (  # Check if knees are aligned under hips\n",
    "            abs(left_knee.x - left_hip.x) < 0.1 and\n",
    "            abs(right_knee.x - right_hip.x) < 0.1\n",
    "        )\n",
    "        legs_vertical = (  # Verify legs are approximately vertical\n",
    "            75 <= left_leg_angle <= 100 and\n",
    "            75 <= right_leg_angle <= 100\n",
    "        )\n",
    "        \n",
    "        # Compile debug information for pose analysis\n",
    "        debug_info = {\n",
    "            \"spine_angle\": f\"{spine_angle:.1f}°\",\n",
    "            \"left_leg_angle\": f\"{left_leg_angle:.1f}°\",\n",
    "            \"right_leg_angle\": f\"{right_leg_angle:.1f}°\",\n",
    "            \"head_tucked\": head_tucked,\n",
    "            \"back_rounded\": back_rounded,\n",
    "            \"knees_under_hips\": knees_under_hips,\n",
    "            \"legs_vertical\": legs_vertical\n",
    "        }\n",
    "        \n",
    "        # Final pose verification\n",
    "        is_marjaryasana = (\n",
    "            head_tucked and\n",
    "            back_rounded and\n",
    "            knees_under_hips and\n",
    "            legs_vertical\n",
    "        )\n",
    "        \n",
    "        return is_marjaryasana, debug_info\n",
    "\n",
    "    def visualize_pose(self, image):\n",
    "        \"\"\"\n",
    "        Draw pose landmarks and connections on the input image.\n",
    "        \n",
    "        Args:\n",
    "            image (numpy.ndarray): Input BGR image\n",
    "            \n",
    "        Returns:\n",
    "            numpy.ndarray: Image with pose landmarks and connections drawn\n",
    "        \"\"\"\n",
    "        # Convert BGR to RGB for MediaPipe processing\n",
    "        image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        results = self.pose.process(image_rgb)\n",
    "        \n",
    "        if results.pose_landmarks:\n",
    "            mp_drawing = mp.solutions.drawing_utils\n",
    "            mp_drawing.draw_landmarks(\n",
    "                image, \n",
    "                results.pose_landmarks,\n",
    "                self.mp_pose.POSE_CONNECTIONS\n",
    "            )\n",
    "        \n",
    "        return image\n",
    "\n",
    "# Example usage of the MarjaryasanaDetector class\n",
    "if __name__ == \"__main__\":\n",
    "    detector = MarjaryasanaDetector()\n",
    "    \n",
    "    # Load and process test image\n",
    "    image = cv2.imread(\"./input_images/pose3.jpg\")\n",
    "    if image is None:\n",
    "        print(\"Error: Could not read image\")\n",
    "    else:\n",
    "        # Detect pose and print results\n",
    "        is_pose, details = detector.detect_pose(image)\n",
    "        print(f\"Is Marjaryasana: {is_pose}\")\n",
    "        print(\"Details:\")\n",
    "        for key, value in details.items():\n",
    "            print(f\"- {key}: {value}\")\n",
    "        \n",
    "        # Generate and save annotated image\n",
    "        annotated_image = detector.visualize_pose(image)\n",
    "        cv2.imwrite(\"pose_annotated.jpg\", annotated_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
